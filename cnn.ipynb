{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de reconocimiento de imagenes satelitales con CNN\n",
    "### Santiago Fandiño Gomez\n",
    "### Juan Manuel Durán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(source_folder, train_folder, test_folder, split_ratio=0.6):\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    files = os.listdir(source_folder)\n",
    "    random.shuffle(files)\n",
    "    num_train = int(len(files) * split_ratio)\n",
    "    for file in files[:num_train]:\n",
    "        src_file = os.path.join(source_folder, file)\n",
    "        dst_file = os.path.join(train_folder, file)\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    print(\"Carpeta de entrenamiento creada con exito\")\n",
    "\n",
    "    for file in files[num_train:]:\n",
    "        src_file = os.path.join(source_folder, file)\n",
    "        dst_file = os.path.join(test_folder, file)\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    print(\"Carpeta de pruebas creada con exito\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images_in_folder(folder_name, target_size):\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "    datagen_config = {\"directory\": folder_name, \"target_size\": target_size}\n",
    "    image_generator = datagen.flow_from_directory(**datagen_config, shuffle=False)\n",
    "    \n",
    "    for i in range(len(image_generator)):\n",
    "        batch_images, batch_labels = image_generator[i]\n",
    "        for j, image in enumerate(batch_images):\n",
    "            if image.shape[:2] != target_size:\n",
    "                resized_image = datagen.load_img(image_generator.filepaths[i * image_generator.batch_size + j], target_size=target_size)\n",
    "                datagen.save_img(image_generator.filepaths[i * image_generator.batch_size + j], resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Las dos funciones anteriores preparan las imagenes para ser trabajadas como prueba y testeo de acuerdo a los parametros que se le entreguen a las funciones. De igual manera, se trabaja una función para asignar un tamaño estandar a las imagenes de las carpetas que se especifique*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU no disponible\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU disponible para usar.\")\n",
    "else:\n",
    "    print(\"GPU no disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11262 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "resize_images_in_folder(\"Data\",(128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Teniendo todas las imagenes con el tamaño solicitado, queda realizar las divisiones de los dataset de imagenes en training y test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta de entrenamiento creada con exito\n",
      "Carpeta de pruebas creada con exito\n",
      "Carpeta de entrenamiento creada con exito\n",
      "Carpeta de pruebas creada con exito\n",
      "Carpeta de entrenamiento creada con exito\n",
      "Carpeta de pruebas creada con exito\n",
      "Carpeta de entrenamiento creada con exito\n",
      "Carpeta de pruebas creada con exito\n",
      "carpetas de entrenamiento y pruebas creadas\n"
     ]
    }
   ],
   "source": [
    "folders = [\"cloudy\", \"desert\", \"green_area\", \"water\"]\n",
    "split_ratio = 0.6\n",
    "\n",
    "for folder in folders:\n",
    "    source_folder = os.path.join(\"Data\", folder)\n",
    "    train_folder = os.path.join(\"Data\", folder + \"_train\")\n",
    "    test_folder = os.path.join(\"Data\", folder + \"_test\")\n",
    "    split_dataset(source_folder, train_folder, test_folder, split_ratio)\n",
    "\n",
    "print(\"carpetas de entrenamiento y pruebas creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Teniendo las imagenes separadas en test y train se puede continuar con la definición de las redes CNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_c = 'Data/cloudy_train/'\n",
    "test_path_c = 'Data/cloudy_test/'\n",
    "train_path_d = 'Data/desert_train/'\n",
    "test_path_d = 'Data/desert_test/'\n",
    "train_path_g = 'Data/green_area_train/'\n",
    "test_path_g = 'Data/green_area_test/'\n",
    "train_path_w = 'Data/water_train/'\n",
    "test_path_w = 'Data/water_test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dimensiones anteriores son siguiendo las recomendaciones del profesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,      # Rotacion entre -20 y 20 grados\n",
    "    width_shift_range=0.1,  # Shift horizontal hasta del 10%\n",
    "    height_shift_range=0.1, # Shift vertical hasta dele 10%\n",
    "    shear_range=0.2,        \n",
    "    zoom_range=0.2,         # Random zoom hasta del 20%\n",
    "    horizontal_flip=True,   # voltear la imagen de manera horizontal\n",
    "    fill_mode='nearest'     # Llenar los nuevos pixeles creados\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
